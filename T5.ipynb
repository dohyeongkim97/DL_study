{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5156eb",
   "metadata": {},
   "source": [
    "## T5(Text-toText Transfer Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7319db",
   "metadata": {},
   "source": [
    "기존 자연어 처리 모델은 대부분 입력 문장을 벡터나 행렬로 변환한 뒤, 이를 통해 출력 문장ㅇ르 생성하는 방식이거나, 출력값이 클래스나 입력값의 일부를 반환하는 형식으로 동작."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bdca6c",
   "metadata": {},
   "source": [
    "T5는 출력을 모두 토큰 시퀀스로 처리하는 Text to Text structure.\n",
    "\n",
    "입력과 출력의 형태를 자유로이 다룰 수 있으며, 구조상 유연성과 확장성이 뛰어남."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127333e8",
   "metadata": {},
   "source": [
    "문장마다 마스크 토큰을 사용하는 Sentinel Token을 사용. <extra_id_0> 이나 <extra_id_1> 처럼, 0부터 99개의 기본값."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb16088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be5009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dohyeong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "news = load_dataset('argilla/news-summary', split='test')\n",
    "df = news.to_pandas().sample(5000, random_state=42)[['text', 'prediction']]\n",
    "df['text'] = 'summarize: ' + df['text']\n",
    "df['prediction'] = df['prediction'].map(lambda x: x[0]['text'])\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac = 1, random_state = 42), [int(0.6*len(df)), int(0.8*len(df))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e578b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9209</th>\n",
       "      <td>summarize: DANANG, Vietnam (Reuters) - Russian...</td>\n",
       "      <td>Putin says had useful interaction with Trump a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>summarize: NEW YORK (Reuters) - A showdown bet...</td>\n",
       "      <td>NY mayor criticizes Trump's closing public atr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7828</th>\n",
       "      <td>summarize:  (This January 3 story was correcte...</td>\n",
       "      <td>Oil business seen in strong position as Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18839</th>\n",
       "      <td>summarize: NEW YORK (Reuters) - Washington sta...</td>\n",
       "      <td>Courts likely to probe Trump's intent in issui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19844</th>\n",
       "      <td>summarize: WASHINGTON (Reuters) - Kristie Kenn...</td>\n",
       "      <td>Kristie Kenney named State Department's new co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>summarize: MOSCOW (Reuters) - President Vladim...</td>\n",
       "      <td>Putin warns North Korea situation on verge of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>summarize: DANANG, Vietnam (Reuters) - It is n...</td>\n",
       "      <td>New Zealand says unclear if TPP agreement can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>summarize: CORALVILLE, Iowa (Reuters) - U.S. R...</td>\n",
       "      <td>Republican candidate Rubio: Fed needs clear ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>summarize: WASHINGTON (Reuters) - It would not...</td>\n",
       "      <td>Germany's Schaeuble presses ECB to unwind loos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>summarize: RIYADH (Reuters) - Saudi Arabia, th...</td>\n",
       "      <td>Saudi Arabia to vet use of Prophet's sayings t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "9209   summarize: DANANG, Vietnam (Reuters) - Russian...   \n",
       "13236  summarize: NEW YORK (Reuters) - A showdown bet...   \n",
       "7828   summarize:  (This January 3 story was correcte...   \n",
       "18839  summarize: NEW YORK (Reuters) - Washington sta...   \n",
       "19844  summarize: WASHINGTON (Reuters) - Kristie Kenn...   \n",
       "...                                                  ...   \n",
       "7920   summarize: MOSCOW (Reuters) - President Vladim...   \n",
       "751    summarize: DANANG, Vietnam (Reuters) - It is n...   \n",
       "16847  summarize: CORALVILLE, Iowa (Reuters) - U.S. R...   \n",
       "1037   summarize: WASHINGTON (Reuters) - It would not...   \n",
       "7596   summarize: RIYADH (Reuters) - Saudi Arabia, th...   \n",
       "\n",
       "                                              prediction  \n",
       "9209   Putin says had useful interaction with Trump a...  \n",
       "13236  NY mayor criticizes Trump's closing public atr...  \n",
       "7828   Oil business seen in strong position as Trump ...  \n",
       "18839  Courts likely to probe Trump's intent in issui...  \n",
       "19844  Kristie Kenney named State Department's new co...  \n",
       "...                                                  ...  \n",
       "7920   Putin warns North Korea situation on verge of ...  \n",
       "751    New Zealand says unclear if TPP agreement can ...  \n",
       "16847  Republican candidate Rubio: Fed needs clear ru...  \n",
       "1037   Germany's Schaeuble presses ECB to unwind loos...  \n",
       "7596   Saudi Arabia to vet use of Prophet's sayings t...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd02f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summarize: DANANG, Vietnam (Reuters) - Russian President Vladimir Putin said on Saturday he had a normal dialogue with U.S. leader Donald Trump at a summit in Vietnam, and described Trump as civil, well-educated, and comfortable to deal with. Putin said that a mooted bilateral sit-down meeting with Trump did not happen at the Asia-Pacific Economic Cooperation summit, citing scheduling issues on both sides and unspecified protocol issues. Putin, at a briefing for reporters at the end of the summit, said there was still a need for further U.S.-Russia contacts, both at the level of heads of state and their officials, to discuss issues including security and economic development.   '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][9209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27d3581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Putin says had useful interaction with Trump at Vietnam summit'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['prediction'][9209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b71f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/dohyeong/miniconda3/Lib/site-packages/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "830b7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe59d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e0482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, tokenizer, device):\n",
    "    source = tokenizer(\n",
    "        text = data.text.tolist(),\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    target = tokenizer(\n",
    "        text = data.prediction.tolist(),\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        pad_to_max_length= True,\n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    \n",
    "    source_ids = source['input_ids'].squeeze().to(device)\n",
    "    source_mask = source['attention_mask'].squeeze().to(device)\n",
    "    target_ids = target['input_ids'].squeeze().to(device)\n",
    "    target_mask = target['attention_mask'].squeeze().to(device)\n",
    "    return TensorDataset(source_ids, source_mask, target_ids, target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb67099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler = data_sampler, batch_size = batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d60973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 8\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f3b0e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79dd294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path= 't5-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dc9841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_dataloader(train_dataset, RandomSampler, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "552b1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_dataloader(valid_dataset, RandomSampler, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e704a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_dataloader(test_dataset, RandomSampler, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bcb7401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[21603,    10,   377,  ...,   141,  5132,     1],\n",
      "        [21603,    10,    71,  ...,  1506,  2542,     1],\n",
      "        [21603,    10,   549,  ...,   888,    12,     1],\n",
      "        ...,\n",
      "        [21603,    10,  8161,  ...,    81,    69,     1],\n",
      "        [21603,    10,  5422,  ...,    19, 11970,     1],\n",
      "        [21603,    10,  6045,  ...,  7402,   593,     1]], device='cuda:0'), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), tensor([[11882, 18486,  2231,  ...,     0,     0,     0],\n",
      "        [ 2523,    31,     7,  ...,     0,     0,     0],\n",
      "        [ 1589,   212,    76,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  571,  2770,  6420,  ...,     0,     0,     0],\n",
      "        [18263,    27,  1967,  ...,     0,     0,     0],\n",
      "        [16870,   789,     3,  ...,     0,     0,     0]], device='cuda:0'), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67929d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dohyeong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from transformers import T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff2fb320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed12d20ff6a4ff9a6afc1e2dde414b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dohyeong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dohyeong\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19a6f529c1e42cfbee4c5bf916c8221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc43be2c4b014579b9e8428fa6ffcd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    pretrained_model_name_or_path= 't5-small'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "510902a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ed36cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f7479e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "        decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "        labels = target_ids[:, 1:].clone().detach()\n",
    "        labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids = source_ids,\n",
    "            attention_mask = source_mask,\n",
    "            decoder_input_ids = decoder_input_ids,\n",
    "            labels = labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63523e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        for source_ids, source_mask, target_ids, target_mask in dataloader:\n",
    "            decoder_input_ids = target_ids[:, :-1].contiguous()\n",
    "            labels = target_ids[:, 1:].clone().detach()\n",
    "            labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "            \n",
    "            outputs = model( \n",
    "                input_ids = source_ids,\n",
    "                attention_mask = source_mask,\n",
    "                decoder_input_ids = decoder_input_ids,\n",
    "                labels = labels,\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            val_loss += loss\n",
    "            \n",
    "        val_loss = val_loss / len(dataloader)\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea84ecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_loss: 4.3346, val_loss: 3.3429\n",
      "\n",
      "model saved\n",
      "epoch: 2, train_loss: 3.4221, val_loss: 2.9161\n",
      "\n",
      "model saved\n",
      "epoch: 3, train_loss: 3.1400, val_loss: 2.7666\n",
      "\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "best_loss = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss = evaluation(model, valid_dataloader)\n",
    "    print(f\"epoch: {epoch+1}, train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), './t5generator.pt')\n",
    "        print()\n",
    "        print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e690b491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27d6c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_headline_text:  a top Republican defends border-adjustable tax provision against Trump criticism. House of Representatives says reform measure to tax imports but not exports remains part of debate.\n",
      "actual_headline:  Republican defends border-adjustment tax after Trump criticism\n",
      "\n",
      "generated_headline_text:  Israeli intelligence minister says Bashar al-Assad is ready to permit Iran to set up Syrian bases. Israel worries that Assad's recent gains have given Iranian and Lebanese Hezbollah allies foothold on Syria front.\n",
      "actual_headline:  After Russia, Iran seeks deal for long-term Syria garrison: Israel\n",
      "\n",
      "generated_headline_text:  U.S. officials seeking way to reverse gains by militant groups. three U.S. service members killed in Afghanistan operations near Pakistan border.\n",
      "actual_headline:  Risk of deeper involvement as U.S. weighs its options in Afghanistan\n",
      "\n",
      "generated_headline_text:  independent human rights investigator says he had information about tortured inmate at Guantanamo Bay detention facility despite Washington banning enhanced interrogation techniques.\n",
      "actual_headline:  U.N. expert says torture persists at Guantanamo Bay; U.S. denies\n",
      "\n",
      "generated_headline_text:  car bomber attacks NATO convoy in southern Afghan city of Kandahar. one civilian killed, four others wounded; no casualties among international forces.\n",
      "actual_headline:  Car bomber attacks NATO convoy in Afghanistan\n",
      "\n",
      "generated_headline_text:  billionaire preparing to fund similar efforts in other cities, former mayor says.\n",
      "actual_headline:  Bloomberg looks West after bankrolling Philadelphia soda tax win\n",
      "\n",
      "generated_headline_text:  Indian capital declares pollution emergency and bans entry of trucks and construction activity. toxic smog hung over city for third day on Thursday, weather office says.\n",
      "actual_headline:  New Delhi declares emergency as toxic smog thickens by the hour\n",
      "\n",
      "generated_headline_text:  Britain wants to keep bans on cheap imitations of locally branded EU produce. european Union wants Britain to protect data stored on continental Europeans after Brexit.\n",
      "actual_headline:  EU tells Britain to protect data or delete them after Brexit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for source_ids, source_mask, target_ids, target_mask in test_dataloader:\n",
    "        generated_ids = model.generate(\n",
    "            input_ids = source_ids, \n",
    "            attention_mask = source_mask,\n",
    "            max_length = 128,\n",
    "            num_beams = 3,\n",
    "            repetition_penalty = 2.5,\n",
    "            length_penalty = 1.0,\n",
    "            early_stopping = True\n",
    "        )\n",
    "        \n",
    "        for generated, target in zip(generated_ids, target_ids):\n",
    "            pred = tokenizer.decode(\n",
    "                generated, skip_special_tokens= True, clean_up_tokenization_spaces= True\n",
    "            )\n",
    "            actual = tokenizer.decode(\n",
    "                target, skip_special_tokens=True, clean_up_tokenization_spaces= True,\n",
    "            )\n",
    "            \n",
    "            print('generated_headline_text: ', pred)\n",
    "            print('actual_headline: ', actual)\n",
    "            print('')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defef151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.4",
   "language": "python",
   "name": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
