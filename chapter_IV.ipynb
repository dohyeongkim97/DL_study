{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b518706c",
   "metadata": {},
   "source": [
    "# Chapter IV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0424e2",
   "metadata": {},
   "source": [
    "Data Collection\n",
    "\n",
    "Feature Engineering\n",
    "\n",
    "Model Transform\n",
    "\n",
    "Early Stopping\n",
    "\n",
    "Batch Normalisation\n",
    "\n",
    "Weight Initialisation\n",
    "\n",
    "Regulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8c056",
   "metadata": {},
   "source": [
    "## Batch Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a938102",
   "metadata": {},
   "source": [
    "ICT(internal covariate shift)를 줄여 과대적합을 방지. CNN or FeedForward Neural Network\n",
    "\n",
    "Normalise by the average and variation of each mini batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf42615",
   "metadata": {},
   "source": [
    "Layer Normalisation, Match Normalisation, Instance Normalisation, Group Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76fa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfaee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 작고 변동성이 거의 없는 경우. 가중치 초기화 매소드를 기본적으로 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af65e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.layer[0].weight)\n",
    "        self.layer[0].bias.data.fill_(0.01)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        self.fc.bias.data.fill_(0.01)\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 크고 변동성이 큰 경우. 가중치 초기화 메소드를 모듈화하여 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6d6926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply: Linear(in_features=2, out_features=1, bias=True)\n",
      "apply: Sigmoid()\n",
      "apply: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n",
      "apply: Linear(in_features=2, out_features=1, bias=True)\n",
      "apply: Net(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(2, 1)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0.01)\n",
    "        print(f'apply: {module}')\n",
    "        \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d57b4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## regulation : 과대적합 문제를 방지하기 위해 사용. 손실함수에 규제(penalty)를 가하는 방식. 일반화성능의 향상 목적. 분산을 낮춰 각 값들의 차이점에 덜 민감하게 만드는 것이 목적."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb10500",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7b639",
   "metadata": {},
   "source": [
    "```\n",
    "for x, y in train_dataloader:\n",
    "    output = model(x)\n",
    "    \n",
    "    _lambda = 0.5\n",
    "    l1_loss = sum(p.abs().sum() for p in model.parameters())\n",
    "    \n",
    "    loss = criterion(output, y) + _lambda * l1_loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee08c4",
   "metadata": {},
   "source": [
    "모델 가중치 절댓값의 합 사용. 모델의 가중치를 모두 계산하여 모델을 갱신해야 하므로 계산복잡도(Computational Complexity) 증가. \n",
    "\n",
    "L1정칙화는 미분이 불가능하므로 역전파를 계산하는 데 더 큰 리소스를 소모. 람다값이 적절하지 않으면 가중치 값이 너무 작아져 모델을 해석하기 어렵게 만들 수 있음.\n",
    "\n",
    "복수 회차 반복하여 최적의 람다값을 탐사. \n",
    "\n",
    "주로 선형 모델에 적용됨. 선형회귀 모델에 L1정칙화를 적용하는 것을 Lasso(Least Absolute Shrinkage and Selection Operator) 회귀라고 칭함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae00b1",
   "metadata": {},
   "source": [
    "### L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a32235e",
   "metadata": {},
   "source": [
    "L2 norm을 사용한 규제. 벡터나 행렬 값의 크기를 계산. 손실함수에 가중치 제곱의 합을 추가하여 과대적합을 방지하도록 규정.\n",
    "\n",
    "L1과 동일하게 모델에 규제를 가함. 하나의 특징이 너무 중요한 요소가 되지 아니하도록 규제를 가하는 것에 의미를 둠.\n",
    "\n",
    "Ridge Regulation이라고 표현. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f87760",
   "metadata": {},
   "source": [
    "```\n",
    "for x, y in train_dataloader:\n",
    "    output = model(x)\n",
    "    \n",
    "    _lambda = 0.5\n",
    "    l2_loss = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "    \n",
    "    loss = criterion(output, y) + _lambda * l2_loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab858aad",
   "metadata": {},
   "source": [
    "### Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7269c",
   "metadata": {},
   "source": [
    "일반적으로 L2 regulation과 동의어. 광의의 의미로는 손실 함수에 규제 항을 추가하는 기술 자체."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aac6a9",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a2e89",
   "metadata": {},
   "source": [
    "경사 하강 알고리즘의 변형. 이전에 이동했던 방향과 기울기의 크기를 고려하여 가중치를 갱신. 지수 가중 이동평균을 사용. 이전 기울기의 일부를 현재 항에 추가하여 가중치를 갱신."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597be08",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e9080",
   "metadata": {},
   "source": [
    "L1 정규화와 L2 정규화를 결합하여 사용하는 방식. L1은 모델이 희박한 가중치를 갖도록, L2는 큰 가중치를 갖지 않도록 규제. 희소성과 작은 가중치의 균형을 찾기 위해 사용하는 방식."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080d1e3",
   "metadata": {},
   "source": [
    "### Drop Out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96acaa6c",
   "metadata": {},
   "source": [
    "일부 노드를 제거하여 사용하는 방식. Voting 효과와 Model Averaging이 가능. 그러나 복수 회차를 통해 voting을 적용해야 하기에 훈련 시간은 늘어남."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543c6bf",
   "metadata": {},
   "source": [
    "```\n",
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 10)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.layer2 = nn.Linear(10, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "```    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d304a2f",
   "metadata": {},
   "source": [
    "### Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914e419",
   "metadata": {},
   "source": [
    "모델 학습 시 기울기가 너무 커지는 것을 방지하는 기술. 가중치 최댓값을 규제하여 최대 임곗값을 초과하지 아니하도록 기울기를 잘라(Clipping) 설정한 임곗값으로 변경. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b866d",
   "metadata": {},
   "source": [
    "```\n",
    "grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "    parameters,\n",
    "    max_norm,\n",
    "    norm_type = 2.0\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5dc746",
   "metadata": {},
   "source": [
    "```\n",
    "for x, y in train_dataloader:\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_rad()\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d90be",
   "metadata": {},
   "source": [
    "# Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a12f03",
   "metadata": {},
   "source": [
    "insert and delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81894da6",
   "metadata": {},
   "source": [
    "insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e6d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef5b3e68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: Those who can imagine anything, can create the impossible.\n",
      "dist: and those creatures who can hardly imagine anything, can create quite the impossible.\n",
      "______________\n",
      "src: We can only see a short distance ahead, but we can see plenty there that needs to be done.\n",
      "dist: so we can only see a short distance ahead, but but we do can see gold plenty there just that needs to finally be properly done.\n",
      "______________\n",
      "src: If a machine is expected to be infallible, it cannot also be intelligent.\n",
      "dist: but if a machine a is thus expected to still be naturally infallible, eventually it cannot also be intelligent.\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'Those who can imagine anything, can create the impossible.',\n",
    "    'We can only see a short distance ahead, but we can see plenty there that needs to be done.',\n",
    "    'If a machine is expected to be infallible, it cannot also be intelligent.'\n",
    "]\n",
    "\n",
    "aug = naw.ContextualWordEmbsAug(model_path = 'bert-base-uncased', action='insert')\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f'src: {text}')\n",
    "    print(f\"dist: {augmented}\")\n",
    "    print(\"______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2968759",
   "metadata": {},
   "source": [
    "swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31bec492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: Those who can imagine anything, can create the impossible.\n",
      "dist: Those who can, imagine anything can create the impossible.\n",
      "______________\n",
      "src: We can only see a short distance ahead, but we can see plenty there that needs to be done.\n",
      "dist: We can only see a short distance ahead, but we can plenty see there that be needs to done.\n",
      "______________\n",
      "src: If a machine is expected to be infallible, it cannot also be intelligent.\n",
      "dist: If a machine is to be expected infallible it cannot, also intelligent be.\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug(action = 'swap')\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f'src: {text}')\n",
    "    print(f\"dist: {augmented}\")\n",
    "    print(\"______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67961a",
   "metadata": {},
   "source": [
    "replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a8f9d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: Those who can imagine anything, can create the impossible.\n",
      "dist: Those who stern opine anything, john create the unimaginable.\n",
      "______________\n",
      "src: We can only see a short distance ahead, but we can see plenty there that needs to be done.\n",
      "dist: We can only if see a myopic distance ahead, but we derriere see plenty there that needs to make up done.\n",
      "______________\n",
      "src: If a machine is expected to be infallible, it cannot also be intelligent.\n",
      "dist: If a machine is expected to follow infallible, information technology cannot also make up intelligent.\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug(aug_src = 'wordnet')\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f'src: {text}')\n",
    "    print(f\"dist: {augmented}\")\n",
    "    print(\"______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fea82",
   "metadata": {},
   "source": [
    "delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aafa2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fde4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: Those who can imagine anything, can create the impossible.\n",
      "dist: The who can imagine ayhig, can ceat the imosble.\n",
      "______________\n",
      "src: We can only see a short distance ahead, but we can see plenty there that needs to be done.\n",
      "dist: We can ol see a shr distance ead, but we can see lent tee ha eds to be done.\n",
      "______________\n",
      "src: If a machine is expected to be infallible, it cannot also be intelligent.\n",
      "dist: If a main is epeed to be nfllibe, it cannot ls be ntliget.\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action = 'delete')\n",
    "augmented_texts = aug.augment(texts)\n",
    "\n",
    "for text, augmented in zip(texts, augmented_texts):\n",
    "    print(f'src: {text}')\n",
    "    print(f\"dist: {augmented}\")\n",
    "    print(\"______________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe3950",
   "metadata": {},
   "source": [
    "back_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b7c8fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-de-en and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "back_translation = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-en-fr',\n",
    "#     to_model_name='Helsinki-NLP/opus-mt-fr-en'\n",
    ")\n",
    "\n",
    "augmented_text = back_translation.augment(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96491126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Those who can imagine anything, can create the impossible.',\n",
       " 'We can only see a short distance ahead, but we can see plenty there that needs to be done.',\n",
       " 'If a machine is expected to be infallible, it cannot also be intelligent.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ab042c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BackTranslationAug' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m back_translation_resolve \u001b[38;5;241m=\u001b[39m naw\u001b[38;5;241m.\u001b[39mBackTranslationAug(\n\u001b[0;32m      2\u001b[0m     from_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHelsinki-NLP/opus-mt-fr-en\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 5\u001b[0m augmented_reverse \u001b[38;5;241m=\u001b[39m \u001b[43mback_translation_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'BackTranslationAug' object is not callable"
     ]
    }
   ],
   "source": [
    "back_translation_resolve = naw.BackTranslationAug(\n",
    "    from_model_name = 'Helsinki-NLP/opus-mt-fr-en'\n",
    ")\n",
    "\n",
    "augmented_reverse = back_translation_resolve(augmented_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9581e199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Texts: ['Those who can imagine anything, can create the impossible.', 'We can only see a short distance in advance, but we can see a lot of it there that needs to be done.', \"If you expect a machine to be infallible, it can't be smart either.\"]\n",
      "Back Translated Texts: [\"Ce qui peut imaginer quoi que ce soit, peut créer l'impossible.\", \"Nous ne pouvons voir qu'une courte distance à l'avance, mais nous pouvons en voir beaucoup là-bas qui doit être fait.\", \"Si vous vous attendez à ce qu'une machine soit infaillible, elle ne peut pas non plus être intelligente.\"]\n"
     ]
    }
   ],
   "source": [
    "# First, create the back translation augmenter from English to French\n",
    "back_translation_en_fr = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-en-fr',\n",
    "    to_model_name='Helsinki-NLP/opus-mt-fr-en'\n",
    ")\n",
    "\n",
    "# Augment the texts\n",
    "augmented_texts = back_translation_en_fr.augment(texts)\n",
    "print(\"Augmented Texts:\", augmented_texts)\n",
    "\n",
    "# Then, create the back translation augmenter from French to English\n",
    "back_translation_fr_en = naw.BackTranslationAug(\n",
    "    from_model_name='Helsinki-NLP/opus-mt-fr-en',\n",
    "    to_model_name='Helsinki-NLP/opus-mt-en-fr'\n",
    ")\n",
    "\n",
    "# Augment the already augmented texts back to English\n",
    "back_translated_texts = back_translation_fr_en.augment(augmented_texts)\n",
    "print(\"Back Translated Texts:\", back_translated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebcb3c0",
   "metadata": {},
   "source": [
    "# Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396875d",
   "metadata": {},
   "source": [
    "library : torchvision, imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69f9d9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512, 512)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "image = Image.open('./images/cat.jpg')\n",
    "transformed_image = transform(image)\n",
    "\n",
    "print(transformed_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a466d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6745, 0.6706, 0.6667, 0.6549, 0.6471, 0.6431, 0.6353, 0.6314, 0.6196,\n",
       "        0.6000, 0.5922, 0.5725, 0.5608, 0.5451, 0.5333, 0.5137, 0.4941, 0.4784,\n",
       "        0.4549, 0.4353, 0.4157, 0.4000, 0.3882, 0.3765, 0.3608, 0.3412, 0.3216,\n",
       "        0.3137, 0.3020, 0.3020, 0.2941, 0.2824, 0.2745, 0.2627, 0.2549, 0.2588,\n",
       "        0.2549, 0.2588, 0.2549, 0.2588, 0.2549, 0.2588, 0.2588, 0.2510, 0.2510,\n",
       "        0.2588, 0.2627, 0.2627, 0.2627, 0.2549, 0.2549, 0.2510, 0.2510, 0.2549,\n",
       "        0.2588, 0.2588, 0.2549, 0.2549, 0.2549, 0.2549, 0.2549, 0.2510, 0.2510,\n",
       "        0.2549, 0.2549, 0.2510, 0.2471, 0.2392, 0.2392, 0.2314, 0.2392, 0.2392,\n",
       "        0.2275, 0.2275, 0.2314, 0.2314, 0.2314, 0.2353, 0.2314, 0.2275, 0.2235,\n",
       "        0.2275, 0.2275, 0.2275, 0.2196, 0.2157, 0.2118, 0.2157, 0.2118, 0.2118,\n",
       "        0.2118, 0.2039, 0.2039, 0.2078, 0.2118, 0.2078, 0.2118, 0.2157, 0.2118,\n",
       "        0.2118, 0.2157, 0.2196, 0.2196, 0.2196, 0.2314, 0.2353, 0.2353, 0.2392,\n",
       "        0.2510, 0.2549, 0.2588, 0.2667, 0.2667, 0.2706, 0.2745, 0.2863, 0.2941,\n",
       "        0.2941, 0.2941, 0.3020, 0.3020, 0.3020, 0.2980, 0.2980, 0.2980, 0.3020,\n",
       "        0.3020, 0.3020, 0.2980, 0.2980, 0.2980, 0.2980, 0.3020, 0.3059, 0.3059,\n",
       "        0.3059, 0.3098, 0.3098, 0.3098, 0.3098, 0.3098, 0.3059, 0.3020, 0.2980,\n",
       "        0.2902, 0.2863, 0.2902, 0.2941, 0.2902, 0.2863, 0.2863, 0.2824, 0.2824,\n",
       "        0.2745, 0.2784, 0.2784, 0.2706, 0.2667, 0.2627, 0.2588, 0.2627, 0.2627,\n",
       "        0.2588, 0.2549, 0.2588, 0.2549, 0.2549, 0.2627, 0.2627, 0.2588, 0.2627,\n",
       "        0.2667, 0.2706, 0.2745, 0.2706, 0.2784, 0.2784, 0.2784, 0.2824, 0.2824,\n",
       "        0.2824, 0.2863, 0.2941, 0.2902, 0.2902, 0.2863, 0.2863, 0.2784, 0.2784,\n",
       "        0.2745, 0.2784, 0.2745, 0.2745, 0.2745, 0.2706, 0.2745, 0.2706, 0.2667,\n",
       "        0.2667, 0.2627, 0.2549, 0.2549, 0.2471, 0.2431, 0.2471, 0.2392, 0.2392,\n",
       "        0.2314, 0.2235, 0.2235, 0.2196, 0.2118, 0.2078, 0.2078, 0.2039, 0.2039,\n",
       "        0.1961, 0.2000, 0.1922, 0.1961, 0.1922, 0.1882, 0.1922, 0.1882, 0.1882,\n",
       "        0.1882, 0.1882, 0.1843, 0.1804, 0.1804, 0.1804, 0.1804, 0.1765, 0.1765,\n",
       "        0.1804, 0.1843, 0.1843, 0.1843, 0.1843, 0.1882, 0.1961, 0.2039, 0.2039,\n",
       "        0.2118, 0.2157, 0.2118, 0.2196, 0.2275, 0.2275, 0.2314, 0.2392, 0.2353,\n",
       "        0.2431, 0.2588, 0.2627, 0.2627, 0.2627, 0.2627, 0.2667, 0.2667, 0.2588,\n",
       "        0.2549, 0.2549, 0.2510, 0.2392, 0.2392, 0.2431, 0.2392, 0.2392, 0.2275,\n",
       "        0.2275, 0.2275, 0.2196, 0.2235, 0.2235, 0.2275, 0.2275, 0.2235, 0.2275,\n",
       "        0.2314, 0.2314, 0.2235, 0.2196, 0.2196, 0.2196, 0.2235, 0.2196, 0.2157,\n",
       "        0.2157, 0.2118, 0.2118, 0.2078, 0.2039, 0.2039, 0.2078, 0.1961, 0.2000,\n",
       "        0.2000, 0.2000, 0.1961, 0.2000, 0.2000, 0.2039, 0.2039, 0.2000, 0.1961,\n",
       "        0.1961, 0.2000, 0.2039, 0.2000, 0.2078, 0.2078, 0.2196, 0.2118, 0.2118,\n",
       "        0.2078, 0.2078, 0.2157, 0.2196, 0.2196, 0.2118, 0.2118, 0.2157, 0.2118,\n",
       "        0.2157, 0.2157, 0.2078, 0.2118, 0.2078, 0.2078, 0.2039, 0.2039, 0.2039,\n",
       "        0.2039, 0.2039, 0.2039, 0.2039, 0.2039, 0.2078, 0.2039, 0.2039, 0.2039,\n",
       "        0.2039, 0.2078, 0.2078, 0.2078, 0.2078, 0.2078, 0.2078, 0.2118, 0.2078,\n",
       "        0.2039, 0.2078, 0.2039, 0.2039, 0.2039, 0.2039, 0.2039, 0.1961, 0.1961,\n",
       "        0.1961, 0.2000, 0.2000, 0.2000, 0.2000, 0.2039, 0.2078, 0.2078, 0.2118,\n",
       "        0.2118, 0.2118, 0.2118, 0.2118, 0.2078, 0.2118, 0.2157, 0.2235, 0.2275,\n",
       "        0.2275, 0.2314, 0.2353, 0.2431, 0.2392, 0.2431, 0.2392, 0.2431, 0.2431,\n",
       "        0.2431, 0.2353, 0.2314, 0.2353, 0.2275, 0.2275, 0.2235, 0.2196, 0.2157,\n",
       "        0.2118, 0.2039, 0.1961, 0.2000, 0.2000, 0.1961, 0.1922, 0.1882, 0.1843,\n",
       "        0.1804, 0.1765, 0.1765, 0.1725, 0.1686, 0.1725, 0.1647, 0.1608, 0.1569,\n",
       "        0.1569, 0.1569, 0.1608, 0.1647, 0.1608, 0.1608, 0.1569, 0.1608, 0.1608,\n",
       "        0.1608, 0.1647, 0.1608, 0.1647, 0.1647, 0.1725, 0.1725, 0.1765, 0.1725,\n",
       "        0.1725, 0.1725, 0.1765, 0.1765, 0.1765, 0.1765, 0.1765, 0.1804, 0.1843,\n",
       "        0.1804, 0.1804, 0.1804, 0.1804, 0.1804, 0.1765, 0.1725, 0.1765, 0.1765,\n",
       "        0.1765, 0.1765, 0.1765, 0.1765, 0.1765, 0.1765, 0.1725, 0.1725, 0.1686,\n",
       "        0.1686, 0.1608, 0.1647, 0.1608, 0.1569, 0.1529, 0.1529, 0.1490, 0.1529,\n",
       "        0.1490, 0.1490, 0.1490, 0.1529, 0.1569, 0.1569, 0.1569, 0.1529, 0.1569,\n",
       "        0.1608, 0.1647, 0.1608, 0.1647, 0.1647, 0.1647, 0.1647, 0.1686, 0.1725,\n",
       "        0.1765, 0.1765, 0.1804, 0.1804, 0.1804, 0.1882, 0.1843, 0.1804, 0.1843,\n",
       "        0.1843, 0.1804, 0.1843, 0.1922, 0.1922, 0.1922, 0.1922, 0.1922, 0.1922,\n",
       "        0.1922, 0.1922, 0.1882, 0.1882, 0.1882, 0.1922, 0.1961, 0.1922])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_image[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8fea2",
   "metadata": {},
   "source": [
    "rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "282dcd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(degrees = 30, expand=False, center=None),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c71249",
   "metadata": {},
   "source": [
    "cut and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37d009dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(size=(512, 512)),\n",
    "        transforms.Pad(padding=50, fill=(127, 127, 255), padding_mode='constant')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267072db",
   "metadata": {},
   "source": [
    "resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca25b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(512, 512))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c1c330",
   "metadata": {},
   "source": [
    "colour transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a8873d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.3, contrast=0.3,\n",
    "            saturation=0.3, hue=0.3\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        transforms.ToPILImage()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc2d8a",
   "metadata": {},
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "497b82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2eb6c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IaaTransforms:\n",
    "    def __init__(self):\n",
    "        self.seq = iaa.Sequential([\n",
    "            iaa.SaltAndPepper(p=(0.03, 0.07)),\n",
    "            iaa.Rain(speed=(0.3, 0.7))\n",
    "        ])\n",
    "        \n",
    "    def __call__(self, images):\n",
    "        iamges = np.array(images)\n",
    "        augmented = self.seq.augment_image(images)\n",
    "        return Image.fromarray(augmented)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    IaaTransforms()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89944eb0",
   "metadata": {},
   "source": [
    "Cutout and Random Erasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ad34c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=1.0, value=0),\n",
    "    transforms.RandomErasing(p=1.0, value='random'),\n",
    "    transforms.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48df18",
   "metadata": {},
   "source": [
    "Mixup and CutMix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120d7ce",
   "metadata": {},
   "source": [
    "Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "945cc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixup:\n",
    "    def __init__(self, target, scale, alpha=0.5, beta=0.5):\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        target = self.target.resize(self.scale)\n",
    "        target = np.array(target)\n",
    "        mix_image = image*self.alpha+target*self.beta\n",
    "        \n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512)),\n",
    "        Mixup(\n",
    "            target = Image.open('./images/dog.jpg'),\n",
    "            scale = (512, 512),\n",
    "            alpha=0.5,\n",
    "            beta=0.5\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff88304",
   "metadata": {},
   "source": [
    "PreTrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f46e1",
   "metadata": {},
   "source": [
    "transfer learning and backbone networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc1c04",
   "metadata": {},
   "source": [
    "Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df79721",
   "metadata": {},
   "source": [
    "A model or a part of it that extract features from input data and give it to final classifier.\n",
    "\n",
    "mentioned from VGG(Very Deep Convolutional Networks for Large Scale Image Recognition), ResNet(Deep Residual Learning for Image Recognition), Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97643c2",
   "metadata": {},
   "source": [
    "Hyper-scale deep learning models like BERT, GPT, VGG-16, ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cf80e",
   "metadata": {},
   "source": [
    "Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20795d08",
   "metadata": {},
   "source": [
    "Re-Use some pre-trained model to improve efficiency of some domains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b18bb0",
   "metadata": {},
   "source": [
    "Dog-Cat model to Wolf-Lion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c09091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.4",
   "language": "python",
   "name": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
