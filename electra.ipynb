{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f9ec1f",
   "metadata": {},
   "source": [
    "## ELECTRA(Efficiently Learning an Encoder that Classifies Token Replacements Accurately)\n",
    "\n",
    "BART / BERT 등에서 사용되는 MLM(Masking Language Modeling) 기법의 입력 마스킹 대신 Generator(생성자)와 Discriminator(판별자)를 사용하는 방식."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4db63",
   "metadata": {},
   "source": [
    "생성자와 판별자를 학습하므로 생성적 적대 신경망(GAN)과 유사한 방식으로 학습이 수행됨.\n",
    "\n",
    "생성 모델은 실제 데이터와 비슷하게 토큰을 생성하여 다른 토큰으로 대체하고, 판별 모델이 생성 모델이 만든 데이터를 입력받아 어떤 데이터가 실제인지 생성 데이터인지를 구분."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e258984",
   "metadata": {},
   "source": [
    "GAN 모델을 사용하여 이전 모델과 비교하여 더 효율적인 학습이 가능. 대규모 데이터세트에서 모델을 더 빠르게 학습 가능함. 생성 모델을 통해 토큰을 생성하므로 다양한 자연어 생성 작업에서 보다 자연스러운 문장을 생성."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6745813",
   "metadata": {},
   "source": [
    "BERT 등에 비해 모델의 매개변수 수가 더 적어 더 빠른 실행과 더 적은 메모리 수요를 충족"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eaf35c",
   "metadata": {},
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083346ca",
   "metadata": {},
   "source": [
    "ELECTRA의 generator와 discriminator는 tf encoder 구조를 따름. 생성자 모델은 입력 문장의 일부 토큰을 마스크, 마스크 처리된 토큰이 어떤 토큰이었는지 예측.\n",
    "\n",
    "판별자 모델은 입력 토큰이 원본 문장 토큰인지를 예측하며 학습."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5615c82",
   "metadata": {},
   "source": [
    "이러한 학습 방식을 RTD(Replaced Token Detection)이라 칭함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6fa61e",
   "metadata": {},
   "source": [
    "사전 학습이 완료되면 생성 모델을 사용하지 아니하고 다운스트림 작업을 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bec91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `nsmc` is already installed at C:\\Users\\dohyeong\\Korpora\\nsmc\\ratings_train.txt\n",
      "[Korpora] Corpus `nsmc` is already installed at C:\\Users\\dohyeong\\Korpora\\nsmc\\ratings_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dohyeong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/dohyeong/miniconda3/Lib/site-packages/\")\n",
    "\n",
    "sys.path\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Korpora import Korpora\n",
    "import torch\n",
    "from transformers import ElectraTokenizer\n",
    "\n",
    "\n",
    "corpus = Korpora.load('nsmc')\n",
    "df = pd.DataFrame(corpus.test).sample(20000, random_state=42)\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6*len(df)), int(0.8*len(df))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d4178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, tokenizer, device):\n",
    "    tokenized = tokenizer(\n",
    "        text = data.text.tolist(),\n",
    "        padding = 'longest',\n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    input_ids = tokenized['input_ids'].to(device)\n",
    "    attention_mask = tokenized['attention_mask'].to(device)\n",
    "    labels = torch.tensor(data.label.values, dtype=torch.long).to(device)\n",
    "    return TensorDataset(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83ba2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler = data_sampler, batch_size = batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642c39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 16\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8949ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bea8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path= 'monologg/koelectra-base-v3-discriminator',\n",
    "    do_lower_case = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bdb29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_dataloader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_dataloader(valid_dataset, RandomSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_dataloader(test_dataset, RandomSampler, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4fee855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | text                                                     |   label |\n",
      "|------:|:---------------------------------------------------------|--------:|\n",
      "| 26891 | 역시 코믹액션은 성룡, 홍금보, 원표 삼인방이 최고지!!     |       1 |\n",
      "| 25024 | 점수 후하게 줘야것네 별 반개~                            |       0 |\n",
      "| 11666 | 오랜만에 느낄수 있는 [감독] 구타욕구.                    |       0 |\n",
      "| 40303 | 본지는 좀 됬지만 극장서 돈주고 본게 아직까지 아까운 영화 |       0 |\n",
      "| 18010 | 징키스칸이란 소재를 가지고 이것밖에 못만드냐             |       0 |\n"
     ]
    }
   ],
   "source": [
    "print(train.head(5).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4256eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([    2,  6511, 14347,  4087,  4665,  4112,  2924,  4806,    16,  3809,\n",
      "         4309,  4275,    16,  3201,  4376,  2891,  4139,  4212,  4007,  6557,\n",
      "         4200,     5,     5,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0], device='cuda:0'), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0], device='cuda:0'), tensor(1, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fb2ff",
   "metadata": {},
   "source": [
    "HuggingFace에서 electra용 모델 제공. 영어 텍스트용 ELECTRA / 한국어 텍스트용 KoELECTRA\n",
    "\n",
    "영문은 google/electra-small | google/electra-base | google/electra-large 로 적용, 국문은 monologg/koelectra-small-v3 | monologg/koelectra-base-v3 으로 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec2fca",
   "metadata": {},
   "source": [
    "ELECTRA는 판별 모델만을 통해 다운스트림 작업을 수행하므로, koelectra-base 모델의 판별 모델인 monologg/koelectra-base-discriminator 모델을 로드.\n",
    "\n",
    "생성 모델을 불러와야 하는 경우라면, monologg/koelectra-base-generator를 통해 로드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb28755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dohyeong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from transformers import ElectraForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22c97f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dohyeong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path = 'monologg/koelectra-base-v3-discriminator',\n",
    "    num_labels = 2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892f5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7355a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc481d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b11fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            labels = labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef4763b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        \n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                labels = labels\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "            accuracy = calc_accuracy(logits, label_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_accuracy += accuracy\n",
    "            \n",
    "        val_loss = val_loss / len(dataloader)\n",
    "        val_accuracy = val_accuracy / len(dataloader)\n",
    "        return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f'epoch: {epoch+1}, train: {train_loss:.4f}, val: {val_loss:.4f}, val_ac: {val_accuracy:.4f}')\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'electra_model.pt')\n",
    "        print()\n",
    "        print('model saved')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7ae6d",
   "metadata": {},
   "source": [
    "### GLUE(General Language Understanding Evaluation) Benchmark dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebddca4d",
   "metadata": {},
   "source": [
    "머신러닝 알고리즘 성능 평가를 위한 표준 데이터셋. 고품질 데이터와 레이블된 결과를 포함. 알고리즘 성능 비교를 위해 공개적인 사용이 가능.\n",
    "\n",
    "문장 수준 / 문서 수준의 이해력을 평가하는 데이터세트. 문장 분류, 유사도 계산, 자연어 추론, 질의응답 등 총 11가지 과제."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.4",
   "language": "python",
   "name": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
